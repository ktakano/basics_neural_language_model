{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BGXi2WF0Hpl"
      },
      "source": [
        "# Short lecture on \"Basics of Neural Language Model\"\n",
        "\n",
        "**Lecturer: Prof. Kosuke Takano, Kanagawa Institute of Technology**\n",
        "\n",
        "This short lecture instructs the basics of neural language model along with simple python codes. The Large Language Model (LLM) such as OpenAI's ChatGPT and Goolge's Gemini are dramatically changing our life and society with their awesome human-like capability, however their mechanism is not so complicated. This lecture aims to focus on basic components to build the LLM and enlighten how they work in a neural network architecture. Student will write small codes of basic functions consisting of neural networks for the natural language processing and deepen the understanding on the principle."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content\n",
        "\n",
        "Day 1:\n",
        "* Basic of neural network\n",
        "* Word embedding\n",
        "* Sequential neural model for Natural Language Processing\n",
        "\n",
        "Day 2:\n",
        "* Sequential neural model for Natural Language Processing (Cont.)\n",
        "* Transformer\n",
        "* Conversation application by GPT"
      ],
      "metadata": {
        "id": "BJN242xWnXJX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Requirement\n",
        "* PC and Internet connection\n",
        "* Google Colaboratory ... Google account is required"
      ],
      "metadata": {
        "id": "FqWwheIJnnKt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WyrJRoHzjQM"
      },
      "source": [
        "## Execution environment\n",
        "\n",
        "Python programs are very version sensitive.Since the execution environment of Colaboratory will be updated at google's discretion, so we need to check it.<br>\n",
        "Python: 3.10.12 (Februrary 27, 2024)<br>\n",
        "TensorFlow: 2.15.0 (Februrary 27, 2024\n",
        "\n",
        "Be sure to specify GPU or TPU as the runtime type."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "id": "rOTii9FkJk3T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1b8fab8-caf1-4637-e6fa-7abf4702da50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5jmSQp1zngl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c946e4d-c532-4288-c6fd-ab4ef9b4258b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part-5"
      ],
      "metadata": {
        "id": "dld0PX_4pETS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural machine translation\n",
        "\n",
        "* Translation function realized using neural network\n",
        "* In 2014, a sequence-to-sequence model using RNN was devised and put into practical use.\n",
        "* Transformer was invented in 2017 and contributes to improving the performance of machine translation."
      ],
      "metadata": {
        "id": "5xYMARaF5KR-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seqence to sequence model\n",
        "\n",
        "* For input sequence data, a sequence-to-seqence (seq-to-seq) model outputs it as another sequence data.\n",
        "* Application: Neural translation, text generation, etc.\n",
        "* A squence to sequence model is also called an encode/decode model because it (1) encodes the input series data, and (2) decodes the encoded result to output the series data.\n",
        "* The encoded result is called a semantic vector.\n",
        "* Since the semantic vector has a fixed length, learning becomes difficult as the length of the input sequence data increases.\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1xnshTq3kThH13CRLV1vbEuRmOvGJ5KAC' width='60%'>\n",
        "</center>\n",
        "<center>\n",
        "Figure 1. Seqence to sequence model\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "z-QL9qFnqX57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying a sequence to sequence model of RNN for machine translation\n",
        "\n",
        "* Input the text to be translated as series data, and output the translated text as series data.\n",
        " * I like cat. You like dog. → ฉัน ชอบ แมว คุณ ชอบ สุนัข\n",
        " * I like cat. You like dog. → 私は猫が好きです。あなたは犬が好きです。\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1JBOuHVL_NuonIraFS1MtGkhdtJm-4rhO' width='70%'>\n",
        "</center>\n",
        "<center>\n",
        "Figure 2. Basic architecture of a sequence to sequence model for machine translation\n",
        "</center>\n"
      ],
      "metadata": {
        "id": "NImfWVfbx9sE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNMvPOBP_H6Q"
      },
      "source": [
        "## Attention\n",
        "* Introduced by Bahdanau, Cho, and Bengio for neural machine translation (2014).\n",
        "* Mechanism to focus on specific features of input data (attention) and emphasize them.\n",
        "* Contributes to improving the performance of sequence-to-sequence models.\n",
        "* Also functions as an important component in Transformers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-attention\n",
        "\n",
        "* Adjust the sequence data to emphasize the elements to be focused on within the same input sequence."
      ],
      "metadata": {
        "id": "EFFEbG8cCe-g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code example**"
      ],
      "metadata": {
        "id": "KXz7bj6PUldd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fXwiiks3RLw"
      },
      "outputs": [],
      "source": [
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "!unzip text8.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTqrq3lG3Zs-"
      },
      "outputs": [],
      "source": [
        "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
        "\n",
        "sentences = Text8Corpus('text8')\n",
        "model = Word2Vec(sentences, vector_size=100)\n",
        "\n",
        "model.save('model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k0iJ8Jh3cCK"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec.load('model.bin')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1v0lS-H4Ti-"
      },
      "outputs": [],
      "source": [
        "text = \"I book a room at the hotel.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGbaS7xY8kML"
      },
      "outputs": [],
      "source": [
        "text = text.lower() # lowercase\n",
        "text = text.replace('.', ' .') # separate period\n",
        "words = text.split(' ') # Split words by white space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNyDgAY78uyA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Creating a self-attention weight matrix\n",
        "a = np.array([])\n",
        "for w1 in words:\n",
        "  for w2 in words:\n",
        "    try:\n",
        "      score = model.wv.similarity(w1, w2)\n",
        "    except:\n",
        "      score = 0\n",
        "\n",
        "    #print(w1, w2, score)\n",
        "    a = np.append(a, score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVUflJoB6fFa"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "length = len(words)\n",
        "\n",
        "attention_matrix = a.reshape(length, length)\n",
        "feature_names = words\n",
        "# Make a heat map of self-attention weights\n",
        "sns.heatmap(attention_matrix, annot=True,\n",
        "            xticklabels=feature_names,\n",
        "            yticklabels=feature_names)\n",
        "\n",
        "# Draw a graph\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Practice 5-1**\n",
        "Draw a heat map of the self-attention weight for the following English sentence.\n",
        "<br><br>\n",
        "Sentence:<br>\n",
        "I cut orages with a knife."
      ],
      "metadata": {
        "id": "2eHJhoY4HOi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention in a sequence to seqence model with RNN\n",
        "* The concatenated outputs of each cell for the input sequence form the sequence of semantic vectors.\n",
        "* When inputting to the decoder cells, considering which part of the context vectors to focus (attend) on, generates the context vector.\n",
        "* Even when the input sequence data is long, the accuracy remains high.\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1Logb1lxDG7YCZ2ndITEHo6AVHtV-OzAZ' width='70%'>\n",
        "</center>\n",
        "<center>\n",
        "Figure 3. Attention in a sequence to seqence model with RNN\n",
        "</center>"
      ],
      "metadata": {
        "id": "IyMmiHN2CU8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture of a RNN-based sequence to seqence model with attention\n",
        "Figure 4 shows an architecture of a RNN-based sequence to seqence model with attention, where attention layer is added in the original architecture as shown in Figure 3.In addition, encode outputs a sequence of semantic vectors that is used for the attention calculation to the input sequence at a decorder.\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1E4EdUJluX2Tad0beRfcdtXA3n6qpifXY' width='70%'>\n",
        "</center>\n",
        "<center>\n",
        "Figure 4. Architecture of a RNN-based sequence to seqence model with attention\n",
        "</center>"
      ],
      "metadata": {
        "id": "vASNKAomMBeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating context vector in attenion calculation\n",
        "\n",
        "Context vector is created in attenion calculation in the following steps.\n",
        "\n",
        "Step-1: For the output of cell $h'_i$ at the decoder, calculate the inner product with each semantic vector $[\\mathbf{h}_1, \\mathbf{h}_2, \\cdots, \\mathbf{h}_n]$ in the semantic vector sequence, and calculate the weight vector $[a_1 , a_2, \\cdots, a_n]$ is obtained.\n",
        "\n",
        "$$ \\mathbf{a} = [a_1 , a_2, \\cdots, a_n] = [\\mathbf{h}_1, \\mathbf{h}_2, \\cdots, \\mathbf{h}_n] \\cdot \\mathbf{h}'_i \\tag{1}$$\n",
        "\n",
        "Step-2: Normalize $[a_1, a_2, \\cdots, a_n]$ applying softmax so that the sum is 1, and create the normalized weight vector $[a'_1, a'_2, \\cdots , a'_n]$\n",
        "\n",
        "$$ [a'_1, a'_2, \\cdots , a'_n] = softmax([a_1 , a_2, \\cdots, a_n]) \\tag{2}$$\n",
        "\n",
        "Step-3: Calculate the weighted sum of each semantic vector in the semantic vector sequence to obtain the context vector $c_i$.\n",
        "\n",
        "$$ \\mathbf{c}_i = a'_1 \\mathbf{h'}_1 + a'_2 \\mathbf{h'}_2 + \\cdots + a'_m \\mathbf{h'}_m = \\sum^m_{k=1}a'_i \\mathbf{h}'_i \\tag{3}$$\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "<img src='https://drive.google.com/uc?export=view&id=1TXp0poDkllbu3sFjBzvJxbKfjSThmPyB' width='70%'>\n",
        "</center>\n",
        "<center>\n",
        "Figure 5. Creation of context vector in attention layer\n",
        "</center>"
      ],
      "metadata": {
        "id": "B9CBxDkzKod0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code example\n",
        "\n",
        "First, we calculate each output $\\mathbf{h}_j$ of the left encoder in a pseudo manner, and create a sequence of semantic vectors using the example input sentence as follows.\n",
        "<br><br>\n",
        "Sentence:<br>\n",
        "I book a room at the hotel."
      ],
      "metadata": {
        "id": "vF7i7dgaR5md"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define RNN_cell0(x, Wx, b) and RNN_cell(x, o, Wx, Wo, b) again."
      ],
      "metadata": {
        "id": "MHFqBKGXa1Cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "wordvec_size = 100\n",
        "hidden_size = 5\n",
        "\n",
        "Wx = np.random.randn(wordvec_size, hidden_size)\n",
        "Wo = np.random.randn(hidden_size, hidden_size)\n",
        "b = np.zeros(hidden_size)"
      ],
      "metadata": {
        "id": "LXJDOWP_Ot0s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN_cell0(x, Wx, b):\n",
        "\n",
        "  _o = np.dot(x, Wx) + b\n",
        "  o = np.tanh(_o)\n",
        "\n",
        "  return o"
      ],
      "metadata": {
        "id": "s9FgN-z3OoPL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RNN_cell(x, o, Wx, Wo, b):\n",
        "\n",
        "  _o = np.dot(o, Wo) + np.dot(x, Wx) + b\n",
        "  o = np.tanh(_o)\n",
        "\n",
        "  return o"
      ],
      "metadata": {
        "id": "35I7X-L1OsyF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train word2vec model using text8 corpus."
      ],
      "metadata": {
        "id": "Y78LovycbF23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://mattmahoney.net/dc/text8.zip\n",
        "!unzip text8.zip"
      ],
      "metadata": {
        "id": "wnJi7jsxaoGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.word2vec import Word2Vec, Text8Corpus\n",
        "\n",
        "sentences = Text8Corpus('text8')\n",
        "model = Word2Vec(sentences, vector_size=100)\n",
        "\n",
        "model.save('model.bin')"
      ],
      "metadata": {
        "id": "AsLDvJfTatQP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec.load('model.bin')"
      ],
      "metadata": {
        "id": "_5Vpr-3-bEta"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = model.wv[\"i\"]\n",
        "x2 = model.wv[\"book\"]\n",
        "x3 = model.wv[\"a\"]\n",
        "x4 = model.wv[\"room\"]\n",
        "x5 = model.wv[\"at\"]\n",
        "x6 = model.wv[\"the\"]\n",
        "x7 = model.wv[\"hotel\"]"
      ],
      "metadata": {
        "id": "SkjZfEhoPS6Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = RNN_cell0(x1, Wx, b)\n",
        "h2 = RNN_cell(x2, h1, Wx, Wo, b)\n",
        "h3 = RNN_cell(x3, h2, Wx, Wo, b)\n",
        "h4 = RNN_cell(x4, h3, Wx, Wo, b)\n",
        "h5 = RNN_cell(x5, h4, Wx, Wo, b)\n",
        "h6 = RNN_cell(x6, h5, Wx, Wo, b)\n",
        "h7 = RNN_cell(x7, h6, Wx, Wo, b)"
      ],
      "metadata": {
        "id": "s9e7DvR2QEqw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(h1)\n",
        "print(h2)"
      ],
      "metadata": {
        "id": "qrDTLmnmcRue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we enter the sentence \"Dinner at the restaurant is my favorite.\" into the decoder on the right. At this example, output $\\mathbf{hd}'_1$ of the first cell in a pseudo manner."
      ],
      "metadata": {
        "id": "n_oPZw7cSC7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# \"Dinner at the restaurant is my favorite.\"\n",
        "\n",
        "y1 = model.wv[\"dinner\"]\n",
        "hd1 = RNN_cell0(y1, Wx, b)"
      ],
      "metadata": {
        "id": "WIP0jWgIQyDR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We generate a context vector paying attention on \"dinner\". First, calculate the weights."
      ],
      "metadata": {
        "id": "X4sMjvhrSLey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a1 = np.dot(h1, hd1)\n",
        "a2 = np.dot(h2, hd1)\n",
        "a3 = np.dot(h3, hd1)\n",
        "a4 = np.dot(h4, hd1)\n",
        "a5 = np.dot(h5, hd1)\n",
        "a6 = np.dot(h6, hd1)"
      ],
      "metadata": {
        "id": "b4ykSNVPRMg7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, generate a context vector for \"dinner\" by computing a weighted sum. In this example, normalization by softmax is not applied for the weight values."
      ],
      "metadata": {
        "id": "4-KuSgLgSrL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c1 = a1 * h1 + a2 * h2 + a3 * h3 + a4 * h4 + a5 * h5 + a6 * h6"
      ],
      "metadata": {
        "id": "MR4V4jeBS2sg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(c1)"
      ],
      "metadata": {
        "id": "XRadDTM-daop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practice 5-2\n",
        "Generate a context vector for paying attention on \"restaurant\". Please use RNN_cell(x, o, Wx, Wo, b) for calculating outputs $\\mathbf{hd}_2$, $\\mathbf{hd}_3$, and so on."
      ],
      "metadata": {
        "id": "Mm6IwtUITRYo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part-6"
      ],
      "metadata": {
        "id": "B5Ul9J077coI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s49voOvohoc4"
      },
      "source": [
        "## Transformer\n",
        "\n",
        "* Vaswaniらが、2017年に提案\n",
        "* 機械翻訳モデルとして提案されたが、広く自然言語処理や画像処理にも利用されている\n",
        "* 英-独翻訳で28.4のBLEUスコア\n",
        " * BLEUスコア: 機械翻訳の精度を評価するためのスコア\n",
        "* RNNのような系列構造を持たず、並列計算による高速化が可能\n",
        "* BERTやGPT-nなどの深層学習モデルもとになっている\n",
        "* 画像処理への適用例としては、Vision Transformer (ViT)がある。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Architecture of Transformer\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1UoTp8e9Y1NCCsr7-m7QlvQBwWRCFgfNt' width='50%'>\n",
        "\n",
        "* Multi-head attention: query, key, valueを入力としたアテンション機構。入力データを分割して、複数の構成にしたものをMulti-headと呼んでいる。\n",
        "* Masked multi-head attention: 後続の単語を参照しないようにするアテンション機構\n",
        "* Positional encoding: 単語の出現位置についての埋め込み情報 (Vaswaniらは、sin関数、cos関数を用いた計算方法を提案)"
      ],
      "metadata": {
        "id": "aahUXhlGMvpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaled Dot-Product Attention\n",
        "\n",
        "* Query、Key、ValueによるAttention機構\n",
        "* ベクトルの大きさで正規化される（scaledされる）\n",
        "* Positional Encodeingを用いて、単語の位置情報を加算する\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1w1Wqzmli6PkzPBXR3tpc02pT5WF3LpxZ' width='50%'>"
      ],
      "metadata": {
        "id": "mcZ6_A-AgDBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-head attention\n",
        "\n",
        "* 入力データを分割して、複数のscaled dot-product attentionで並列処理\n",
        "* 出力は、各attentionの出力(ベクトル形式)を横方向に連結(concat)\n",
        "\n",
        "<img src='https://drive.google.com/uc?export=view&id=1cpMJTclA31kwMsLZN_Jv19cvXjp8ETEN' width='30%'>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wkfVKpgBhKxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positional encoding\n",
        "* 文章中の各単語(トークン)に位置情報を与える処理"
      ],
      "metadata": {
        "id": "OV1tvf7GVHgc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code example**"
      ],
      "metadata": {
        "id": "y-99tOYBfwSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def positional_encoding(pos, i, dim):\n",
        "  if i//2 == 0:\n",
        "    return np.sin(pos/10000**(1/dim))\n",
        "  else:\n",
        "    return np.cos(pos/10000**((i-1)/dim))"
      ],
      "metadata": {
        "id": "h3vA0IUmVGrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1番目の(単語の)位置情報を100次元ベクトルで生成してみます。"
      ],
      "metadata": {
        "id": "zhw_6dC0VgP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 100):\n",
        "  print(positional_encoding(1, i, 100))"
      ],
      "metadata": {
        "id": "f9ruldImVosv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Practice 6-1**\n",
        "2番目と3番目の位置情報を100次元ベクトルで生成してみましょう。"
      ],
      "metadata": {
        "id": "vdmQczfGWoYU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code example**\n",
        "30番目までの位置情報を配列(30個 x 100次元ベクトル)に格納します。その後可視化します。"
      ],
      "metadata": {
        "id": "gRqoStonV1cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pe = np.zeros((30, 100))\n",
        "for i in range(0,30):\n",
        "  for j in range(0, 100):\n",
        "    pe[i][j] = positional_encoding(i, j, 100)\n",
        "\n",
        "print(pe)"
      ],
      "metadata": {
        "id": "fEBMnfDMVrvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sns.heatmap(pe)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8dIcaTn0WDVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"I book room at the hotel.\"の各単語にPositional Encodingを埋め込んでみます。"
      ],
      "metadata": {
        "id": "y08t_uwoXYK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xe1 = x1 + pe[0] # I\n",
        "xe2 = x2 + pe[1] # book\n",
        "\n",
        "print(xe1.shape)\n",
        "print(xe2.shape)"
      ],
      "metadata": {
        "id": "Z2YK8ihnXxcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Practice 6-2**\n",
        "残りの単語\"room\"、\"at\"、\"the\"、\"hotel\"についても、Posisional Encodingを埋め込んだベクトルを生成してみましょう。"
      ],
      "metadata": {
        "id": "6j3wNMizYRRo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying Transformer encoder for sentiment analysis\n",
        "\n",
        "Transformerエンコーダを用いて、IMDBデータセットの映画レビュー文章を分類します。"
      ],
      "metadata": {
        "id": "r2HfScUYN6IM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Code example**"
      ],
      "metadata": {
        "id": "psgcywKAgJfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHtrgk4khoBe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask)\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DRm4E2Whufo"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000 # Number of words\n",
        "embed_dim = 256 # Dimension of embedding\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-nTFpZwnLwm"
      },
      "outputs": [],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkicmeUYncJM"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rv2efUOInXUI"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for item in int_train_ds:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "BZcDANRrv-YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi0b9CcYkNDA"
      },
      "outputs": [],
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "id": "i1DFeFymapZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Practice 6-3**\n",
        "* Increase the number of epochs to 10 in the Transformer encoder and check if the classification accuracy is improved. (If it takes longer to execute, you can reduce the number of epochs.)\n",
        "* In addition to SimpleRNN, LSTM, and GRU, which we checked last time, compare and discuss the classification accuracy of four models including Transformer encoder. Furthermore, let's compare by also focusing on the number of model parameters.\n",
        "\n"
      ],
      "metadata": {
        "id": "q2UJKn_ALzUZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMK1SPj4zebm"
      },
      "source": [
        "## Reference\n",
        "* Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, https://arxiv.org/abs/1810.04805v1, 2018.\n",
        "* Keras official Website, https://keras.io/examples/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}